# Lab 3: Batchnorm, Dropout and Residual

尝试在基础/深层MLP中引入：

- [x] Batch Normalization
- [x] Dropout
- [x] Residual Block

并对比这些方法对模型训练效果的影响（在 `CIFAR-10` 数据集上测试）。

- [实验代码](https://github.com/Charles-T-T/Multimedia-Technology/blob/main/labs/lab3/src/assignment3_hw_batchnorm_dropout_residual.ipynb)